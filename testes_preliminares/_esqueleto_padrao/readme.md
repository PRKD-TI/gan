# ğŸ§ª Primeiro Teste - Esqueleto PadrÃ£o da GAN

Este repositÃ³rio contÃ©m a estrutura mÃ­nima de uma **GAN para costura de imagens**, pensada como esqueleto de testes iniciais. A ideia Ã© ter uma base simples, limpa e fÃ¡cil de expandir.

---

## ğŸ“‚ Estrutura de DiretÃ³rios

```
.
â”œâ”€â”€ generator/
â”‚   â””â”€â”€ gen_base.py          # Gerador base (Encoder-Decoder simples)
â”œâ”€â”€ discriminator/
â”‚   â””â”€â”€ disc_base.py         # Discriminador base (PatchGAN simples)
â”œâ”€â”€ testes/
â”‚   â””â”€â”€ _esqueleto_padrao/
â”‚       â”œâ”€â”€ train.py         # Script principal de treino
â”‚       â””â”€â”€ train_loop.py    # Loop de treinamento
â””â”€â”€ utils/
    â””â”€â”€ dataset_utils.py     # Dataset customizado para costura de imagens
```

---

## ğŸ¨ Gerador - `generator/gen_base.py`

O gerador inicial (`BasicGenerator`) Ã© baseado em uma **arquitetura Encoder-Decoder simples** que recebe duas imagens (`part1`, `part2`) e concatena internamente.

- Entrada: `part1` (RGB), `part2` (RGB)
- ConcatenaÃ§Ã£o: `[B, 3, H, W] + [B, 3, H, W] -> [B, 6, H, W]`
- Encoder: 3 camadas de convoluÃ§Ã£o com downsampling
- Bottleneck: camada profunda para aprendizado de contexto
- Decoder: 3 camadas de `ConvTranspose` para upsampling
- SaÃ­da final: imagem RGB `[B, 3, H, W]` com ativaÃ§Ã£o `Tanh`

Esse modelo serve apenas como **baseline experimental**.

### Exemplo de uso

```python
import torch
from generator.gen_base import BasicGenerator

# Criar instÃ¢ncia do gerador
generator = BasicGenerator()

# Gerar imagens falsas a partir de partes artificiais
part1 = torch.randn(1, 3, 64, 96)
part2 = torch.randn(1, 3, 64, 96)
fake = generator(part1, part2)

print(fake.shape)  # -> torch.Size([1, 3, 64, 96])
```

---

## ğŸ•µï¸ Discriminador - `discriminator/disc_base.py`

O discriminador inicial (`BasicDiscriminator`) segue a ideia de um **PatchGAN condicional**.

- Entrada:

  - `part1` (RGB)
  - `part2` (RGB)
  - imagem real ou gerada (RGB)
  - Concatenados: `[B, 9, H, W]`

- Arquitetura:

  - 4 camadas convolucionais progressivamente mais profundas (64 â†’ 512 filtros)
  - BatchNorm a partir da 2Âª camada
  - AtivaÃ§Ã£o **LeakyReLU(0.2)** em todas as camadas
  - Camada final `Conv2d(512 â†’ 1)` gera o mapa de real/falso

- SaÃ­da:

  - Um **mapa de patches** `[B, 1, H/16, W/16]`
  - Cada valor representa a confianÃ§a de real/falso em um patch da imagem

Esse modelo fornece supervisÃ£o local, forÃ§ando o gerador a criar detalhes realistas em regiÃµes especÃ­ficas.

### Exemplo de uso

```python
import torch
from discriminator.disc_base import BasicDiscriminator

# Criar instÃ¢ncia do discriminador
discriminator = BasicDiscriminator()

# Partes e imagem fake (mesmo tamanho)
part1 = torch.randn(1, 3, 64, 96)
part2 = torch.randn(1, 3, 64, 96)
fake = torch.randn(1, 3, 64, 96)

# Concatenar para o discriminador
inp = torch.cat([part1, part2, fake], dim=1)
out = discriminator(inp)

print(out.shape)  # -> torch.Size([1, 1, 7, 11]) (exemplo)
```

---

## ğŸ” Loop de Treinamento - `train_loop.py`

O loop de treinamento implementa a lÃ³gica bÃ¡sica:

1. **Forward Generator**

   ```python
   fake = generator(part1, part2)
   ```

2. **Treino do Discriminador**

   - Real loss (com ground truth)
   - Fake loss (com imagens geradas)

3. **Treino do Gerador**

   - Objetivo: enganar o discriminador (adversarial loss)
   - Inclui **L1 Loss** para proximidade com a ground truth

4. **Zerar gradientes corretamente**:

   ```python
   optimizer_G.zero_grad()
   optimizer_D.zero_grad()
   ```

5. **Otimizadores**

   - Ambos usam **Adam** (`lr=0.0002, betas=(0.5, 0.999)`)

---

## ğŸ“Š MÃ©tricas

Para este primeiro teste, mÃ©tricas foram simplificadas:

- `Loss_G`: perda do gerador (adversarial + L1)
- `Loss_D`: perda do discriminador (real + fake)

Futuramente podemos incluir:

- PSNR, SSIM, MS-SSIM
- LPIPS

---

## ğŸš€ PrÃ³ximos Passos

1. Validar o treinamento com dataset reduzido
2. Visualizar algumas amostras geradas
3. Incluir mÃ©tricas de qualidade
4. Evoluir para arquiteturas mais profundas (UNet, DualEncoder, atenÃ§Ã£o, etc.)

---

